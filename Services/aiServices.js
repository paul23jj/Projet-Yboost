require('dotenv').config();

async function generateImage(prompt) {
    console.log(`ü§ñ Envoi du prompt √† l'IA : "${prompt}"`);

    try {
        const response = await fetch(process.env.HF_API_URL, {
            headers: {
                Authorization: `Bearer ${process.env.HF_API_KEY}`,
                "Content-Type": "application/json",
            },
            method: "POST",
            body: JSON.stringify({
                inputs: prompt,
                // Param√®tres optionnels pour am√©liorer le r√©sultat
                parameters: {
                    negative_prompt: "blurry, low quality, text, watermark, bad anatomy",
                }
            }),
        });

        // Gestion des erreurs sp√©cifiques √† Hugging Face
        if (!response.ok) {
            const errorDetails = await response.json(); // Souvent HF renvoie du JSON en cas d'erreur
            throw new Error(`Erreur API (${response.status}): ${JSON.stringify(errorDetails)}`);
        }

        // Si tout va bien, l'API renvoie une image binaire (Blob/Buffer)
        const arrayBuffer = await response.arrayBuffer();
        return Buffer.from(arrayBuffer); // On convertit en Buffer Node.js

    } catch (error) {
        console.error("‚ùå Erreur dans aiService :", error.message);
        throw error; // On renvoie l'erreur pour que le contr√¥leur la g√®re
    }
}

module.exports = { generateImage };

if (response.status === 503) {
    const data = await response.json();
    return res.status(503).json({
        success: false,
        error: "Le mod√®le est en train de chauffer...",
        estimated_time: data.estimated_time
    });
} // le model s'endort si il n'est pas utilis√© au bout de 1 heure